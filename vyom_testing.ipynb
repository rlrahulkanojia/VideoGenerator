{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8145b37f-90dc-496e-8abe-c815582ce57a",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0cd6e87-004d-43fa-a50e-5c5896973f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vyom_utils import Generator_4secs, Generator_9secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ffb62-8291-401e-b07b-cce07a600d87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generating 4 secs Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c32d6-fd83-43d4-8a0d-3fdc5f5e407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case you need to save the prompts from the notebook. Uncomment the code below.\n",
    "# prompts = \"\"\"\n",
    "# A horse running on plains, beautiful sunlight behind it. \\n\n",
    "# \"\"\"\n",
    "# # Open the file in write mode ('w') which will create the file if it doesn't exist\n",
    "# with open(\"vyom_prompts_1.txt\", 'w') as file:\n",
    "#     # Write the string to the file\n",
    "#     file.write(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2518f48-fbdb-435b-9b97-b55b4e1686bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = open(\"vyom_prompts.txt\").readlines()\n",
    "for prompt in prompts:\n",
    "    if prompt==\"\\n\":\n",
    "        continue\n",
    "    print(f\"Prompt : {prompt}\")\n",
    "    generator = Generator_4secs(prompt)\n",
    "    generator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038ba0d-7072-45ce-8b97-d49fc9236aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea757ee8-1296-4572-8966-98738fbd2e80",
   "metadata": {},
   "source": [
    "### Generating 9 Secs video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f8a0f-d38b-40a5-bc3a-a22ac5e34d52",
   "metadata": {},
   "source": [
    "##### This section creates videos with 10 secs video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56adf7e-e759-437b-b917-d7a6835cc22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt : A woman wearing a blue sundress sitting and having a picnic in a field of sunflowers, summer time, cinema\n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-21 07:37:38,161] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 07:37:38,161] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 07:37:38,168] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 07:37:44,195] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 07:37:47,935] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 07:37:56,338] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 07:37:56,846] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 07:37:56,847] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||A woman wearing a blue sundress sitting and having a picnic in a field of sunflowers, summer time, cinema ...\n",
      "[2024-05-21 07:37:59,385] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 07:42:48,231] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_woman_wearing_a_blue_sundress_sitting_and_having_a_picnic_in_a_field_of_sunflowers_summer_time_cinema_00.mp4:\n",
      "[2024-05-21 07:42:48,232] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_woman_wearing_a_blue_sundress_sitting_and_having_a_picnic_in_a_field_of_sunflowers_summer_time_cinema_00.mp4\" to \"workspace/experiments/vyom_9sec_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/1.mp4\n",
      "[2024-05-21 07:42:50,737] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 07:42:50,737] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 07:42:50,744] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 07:42:56,768] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 07:43:00,507] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 07:43:08,962] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 07:43:09,463] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 07:43:09,463] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||A woman wearing a blue sundress sitting and having a picnic in a field of sunflowers, summer time, cinema ...\n",
      "[2024-05-21 07:43:11,987] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 07:48:00,668] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_woman_wearing_a_blue_sundress_sitting_and_having_a_picnic_in_a_field_of_sunflowers_summer_time_cinema_00.mp4:\n",
      "[2024-05-21 07:48:00,669] INFO: Congratulations! The inference is completed!\n",
      "Run 2 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_woman_wearing_a_blue_sundress_sitting_and_having_a_picnic_in_a_field_of_sunflowers_summer_time_cinema_00.mp4\" to \"workspace/experiments/vyom_9sec_list/2.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/2.mp4\n",
      "[2024-05-21 07:48:03,159] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 07:48:03,160] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 07:48:03,167] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 07:48:10,244] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 07:48:13,970] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 07:48:22,426] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 07:48:22,943] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 07:48:22,943] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||A woman wearing a blue sundress sitting and having a picnic in a field of sunflowers, summer time, cinema ...\n",
      "[2024-05-21 07:48:25,462] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 07:53:13,971] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_woman_wearing_a_blue_sundress_sitting_and_having_a_picnic_in_a_field_of_sunflowers_summer_time_cinema_00.mp4:\n",
      "[2024-05-21 07:53:13,972] INFO: Congratulations! The inference is completed!\n",
      "Run 3 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_woman_wearing_a_blue_sundress_sitting_and_having_a_picnic_in_a_field_of_sunflowers_summer_time_cinema_00.mp4\" to \"workspace/experiments/vyom_9sec_list/3.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/3.mp4\n",
      "1.mp4\n",
      "2.mp4\n",
      "3.mp4\n",
      "Concatenated video saved successfully!\n",
      "Prompt : A knight fighting in a gruesome war, smoke filled skies, swords and shields, medival aesthetic, anime aes\n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-21 07:53:29,475] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 07:53:29,475] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 07:53:29,484] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 07:53:35,521] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 07:53:39,199] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 07:53:47,610] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 07:53:48,125] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 07:53:48,125] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||A knight fighting in a gruesome war, smoke filled skies, swords and shields, medival aesthetic, anime aes ...\n",
      "[2024-05-21 07:53:50,651] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 07:58:39,115] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_knight_fighting_in_a_gruesome_war_smoke_filled_skies_swords_and_shields_medival_aesthetic_anime_aes_00.mp4:\n",
      "[2024-05-21 07:58:39,115] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_knight_fighting_in_a_gruesome_war_smoke_filled_skies_swords_and_shields_medival_aesthetic_anime_aes_00.mp4\" to \"workspace/experiments/vyom_9sec_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/1.mp4\n",
      "[2024-05-21 07:58:41,651] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 07:58:41,651] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 07:58:41,658] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 07:58:47,705] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 07:58:51,387] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 07:58:59,815] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 07:59:00,333] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 07:59:00,334] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||A knight fighting in a gruesome war, smoke filled skies, swords and shields, medival aesthetic, anime aes ...\n",
      "[2024-05-21 07:59:02,855] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 08:03:51,102] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_knight_fighting_in_a_gruesome_war_smoke_filled_skies_swords_and_shields_medival_aesthetic_anime_aes_00.mp4:\n",
      "[2024-05-21 08:03:51,103] INFO: Congratulations! The inference is completed!\n",
      "Run 2 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_knight_fighting_in_a_gruesome_war_smoke_filled_skies_swords_and_shields_medival_aesthetic_anime_aes_00.mp4\" to \"workspace/experiments/vyom_9sec_list/2.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/2.mp4\n",
      "[2024-05-21 08:03:53,632] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 08:03:53,632] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 08:03:53,639] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 08:03:59,756] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 08:04:03,471] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 08:04:11,939] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 08:04:12,462] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 08:04:12,462] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||A knight fighting in a gruesome war, smoke filled skies, swords and shields, medival aesthetic, anime aes ...\n",
      "[2024-05-21 08:04:14,994] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 08:09:03,589] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_knight_fighting_in_a_gruesome_war_smoke_filled_skies_swords_and_shields_medival_aesthetic_anime_aes_00.mp4:\n",
      "[2024-05-21 08:09:03,590] INFO: Congratulations! The inference is completed!\n",
      "Run 3 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_knight_fighting_in_a_gruesome_war_smoke_filled_skies_swords_and_shields_medival_aesthetic_anime_aes_00.mp4\" to \"workspace/experiments/vyom_9sec_list/3.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/3.mp4\n",
      "1.mp4\n",
      "2.mp4\n",
      "3.mp4\n",
      "Concatenated video saved successfully!\n",
      "Prompt : Marine life in the Indian ocean with divers, rennaisance style\n",
      "\n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-21 08:09:18,760] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 08:09:18,760] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 08:09:18,767] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 08:09:24,798] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 08:09:28,489] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 08:09:36,982] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 08:09:37,500] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 08:09:37,500] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||Marine life in the Indian ocean with divers, rennaisance style ...\n",
      "[2024-05-21 08:09:40,032] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 08:14:28,795] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Marine_life_in_the_Indian_ocean_with_divers_rennaisance_style_00.mp4:\n",
      "[2024-05-21 08:14:28,795] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Marine_life_in_the_Indian_ocean_with_divers_rennaisance_style_00.mp4\" to \"workspace/experiments/vyom_9sec_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/1.mp4\n",
      "[2024-05-21 08:14:31,336] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 08:14:31,336] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 08:14:31,343] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 08:14:37,430] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 08:14:41,208] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 08:14:49,977] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 08:14:50,494] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 08:14:50,494] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||Marine life in the Indian ocean with divers, rennaisance style ...\n",
      "[2024-05-21 08:14:53,026] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 08:19:41,760] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Marine_life_in_the_Indian_ocean_with_divers_rennaisance_style_00.mp4:\n",
      "[2024-05-21 08:19:41,761] INFO: Congratulations! The inference is completed!\n",
      "Run 2 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Marine_life_in_the_Indian_ocean_with_divers_rennaisance_style_00.mp4\" to \"workspace/experiments/vyom_9sec_list/2.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/2.mp4\n",
      "[2024-05-21 08:19:44,330] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 08:19:44,330] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 08:19:44,337] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 08:19:50,379] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 08:19:54,047] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 08:20:02,480] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 08:20:02,995] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 08:20:02,995] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||Marine life in the Indian ocean with divers, rennaisance style ...\n",
      "[2024-05-21 08:20:05,520] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 08:24:54,186] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Marine_life_in_the_Indian_ocean_with_divers_rennaisance_style_00.mp4:\n",
      "[2024-05-21 08:24:54,187] INFO: Congratulations! The inference is completed!\n",
      "Run 3 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Marine_life_in_the_Indian_ocean_with_divers_rennaisance_style_00.mp4\" to \"workspace/experiments/vyom_9sec_list/3.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/3.mp4\n",
      "1.mp4\n",
      "2.mp4\n",
      "3.mp4\n",
      "Concatenated video saved successfully!\n",
      "Prompt : Paris in the rain, calming, cinematic, 50 mm lens, evening, cheerful.\n",
      "\n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-21 08:25:11,693] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 08:25:11,694] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 08:25:11,701] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 08:25:17,764] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 08:25:21,493] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 08:25:29,933] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 08:25:30,445] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 08:25:30,445] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||Paris in the rain, calming, cinematic, 50 mm lens, evening, cheerful. ...\n",
      "[2024-05-21 08:25:32,982] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 08:30:21,631] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Paris_in_the_rain_calming_cinematic_50_mm_lens_evening_cheerful_00.mp4:\n",
      "[2024-05-21 08:30:21,631] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Paris_in_the_rain_calming_cinematic_50_mm_lens_evening_cheerful_00.mp4\" to \"workspace/experiments/vyom_9sec_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/1.mp4\n",
      "[2024-05-21 08:30:24,203] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 08:30:24,203] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 08:30:24,210] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 08:30:30,265] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 08:30:33,923] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 08:30:42,303] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 08:30:42,809] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 08:30:42,809] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||Paris in the rain, calming, cinematic, 50 mm lens, evening, cheerful. ...\n",
      "[2024-05-21 08:30:45,326] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 08:35:33,812] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Paris_in_the_rain_calming_cinematic_50_mm_lens_evening_cheerful_00.mp4:\n",
      "[2024-05-21 08:35:33,812] INFO: Congratulations! The inference is completed!\n",
      "Run 2 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Paris_in_the_rain_calming_cinematic_50_mm_lens_evening_cheerful_00.mp4\" to \"workspace/experiments/vyom_9sec_list/2.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/2.mp4\n",
      "[2024-05-21 08:35:36,359] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 08:35:36,359] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 08:35:36,366] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 08:35:42,388] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 08:35:46,096] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 08:35:54,499] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 08:35:55,008] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 08:35:55,008] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||Paris in the rain, calming, cinematic, 50 mm lens, evening, cheerful. ...\n",
      "[2024-05-21 08:35:57,531] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 08:40:45,996] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Paris_in_the_rain_calming_cinematic_50_mm_lens_evening_cheerful_00.mp4:\n",
      "[2024-05-21 08:40:45,996] INFO: Congratulations! The inference is completed!\n",
      "Run 3 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_Paris_in_the_rain_calming_cinematic_50_mm_lens_evening_cheerful_00.mp4\" to \"workspace/experiments/vyom_9sec_list/3.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/3.mp4\n",
      "1.mp4\n",
      "2.mp4\n",
      "3.mp4\n",
      "Concatenated video saved successfully!\n",
      "Prompt : A sci-fi Seoul in the future with flying cars, cinematic, hyper realistic.\n",
      "\n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-21 08:41:02,445] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 08:41:02,446] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 08:41:02,452] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 08:41:08,514] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 08:41:12,158] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 08:41:20,585] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 08:41:21,097] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 08:41:21,097] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||A sci-fi Seoul in the future with flying cars, cinematic, hyper realistic. ...\n",
      "[2024-05-21 08:41:23,623] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-21 08:46:12,266] INFO: Save video to dir workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_scifi_Seoul_in_the_future_with_flying_cars_cinematic_hyper_realistic_00.mp4:\n",
      "[2024-05-21 08:46:12,267] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_list/vyom_9sec_01_00_A_scifi_Seoul_in_the_future_with_flying_cars_cinematic_hyper_realistic_00.mp4\" to \"workspace/experiments/vyom_9sec_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_list/1.mp4\n",
      "[2024-05-21 08:46:14,811] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_list/log_00.txt'}\n",
      "[2024-05-21 08:46:14,812] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-21 08:46:14,818] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-21 08:46:20,992] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-21 08:46:24,706] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-21 08:46:33,175] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-21 08:46:33,683] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-21 08:46:33,683] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec.jpg|||A sci-fi Seoul in the future with flying cars, cinematic, hyper realistic. ...\n",
      "[2024-05-21 08:46:36,210] INFO: GPU Memory used 16.78 GB\n"
     ]
    }
   ],
   "source": [
    "prompts = open(\"vyom_prompts.txt\").readlines()\n",
    "for prompt in prompts:\n",
    "    if prompt==\"\\n\":\n",
    "        continue\n",
    "    prompt=prompt[:105]\n",
    "    print(f\"Prompt : {prompt}\")\n",
    "    generator = Generator_9secs(prompt)\n",
    "    generator.run_iterations(number_of_iterations=3) #Each iteration increases the video duration by 4 secs ( 32 frames )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2166b-3670-441d-92b7-a2c73a321fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3dca45-da16-4bae-9701-ecfc237781d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58b724d1-a1ad-4099-8a38-1d07d7f6fb41",
   "metadata": {},
   "source": [
    "### PROMPTS\n",
    "A horse running on plains, beautiful sunlight behind it.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cinematic shot, woman in arctic clothing walking towards outpost, detailed face, cinematic contour lighting, building sitting on snowy hill in nepal, in the style of surrealistic dream-like imagery, ethereal cloudscapes, made of mist, conceptual installation art, hdr\n",
    "\n",
    "\n",
    "a girl holding a video camera to her head, in the style of hustlewave, 1980s, post-internet aesthetics, reefwave, wetcore, transavanguardia, childlike\n",
    "\n",
    "\n",
    "cinematic shot, greek temple on the top of cliff, electric lightsmoke & wire phenomenas, biblical event, movie aesthetic, super detailed, muted colours\n",
    "\n",
    "\n",
    "Photorealistic Busstop in Japan, Sakura Treens, Lofi Aesthetic, Minimalistic Cinematic Advertisement Aesthetic\n",
    "\n",
    "Arctic Norway Landscape showing Snowy Trollstung, muted colors, cinematic contour lighting, low contrast ProLog, awardwinning composition, chromatic aberration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b050ebc8-f47f-4f38-b826-aa6bf66697c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
