{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8145b37f-90dc-496e-8abe-c815582ce57a",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0cd6e87-004d-43fa-a50e-5c5896973f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vyom_llm_utils import Generator_4secs, Generator_9secs, llm_prompt_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ffb62-8291-401e-b07b-cce07a600d87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generating 4 secs Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c32d6-fd83-43d4-8a0d-3fdc5f5e407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case you need to save the prompts from the notebook. Uncomment the code below.\n",
    "# prompts = \"\"\"\n",
    "# A horse running on plains, beautiful sunlight behind it. \\n\n",
    "# \"\"\"\n",
    "# # Open the file in write mode ('w') which will create the file if it doesn't exist\n",
    "# with open(\"vyom_prompts_1.txt\", 'w') as file:\n",
    "#     # Write the string to the file\n",
    "#     file.write(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2518f48-fbdb-435b-9b97-b55b4e1686bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = open(\"vyom_prompts-llm.txt\").readlines()\n",
    "for prompt in prompts:\n",
    "    if prompt==\"\\n\":\n",
    "        continue\n",
    "    print(f\"Original Prompt : {prompt}\")\n",
    "    generated_prompts = llm_prompt_generator(prompt)\n",
    "    image_prompt = generated_prompts[\"Image_prompt\"]\n",
    "    video_prompt = generated_prompts[\"Video_prompt\"]\n",
    "    print(\"Image prompt\", image_prompt )\n",
    "    print(\"Video prompt\", video_prompt )\n",
    "    generator = Generator_4secs(\n",
    "                    image_prompt=image_prompt,\n",
    "                    video_prompt=video_prompt\n",
    "                )\n",
    "    generator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038ba0d-7072-45ce-8b97-d49fc9236aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 secs output videos in : workspace/experiments/vyom_4sec_llm_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea757ee8-1296-4572-8966-98738fbd2e80",
   "metadata": {},
   "source": [
    "### Generating 9 Secs video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f8a0f-d38b-40a5-bc3a-a22ac5e34d52",
   "metadata": {},
   "source": [
    "##### This section creates videos with 10 secs video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2166b-3670-441d-92b7-a2c73a321fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prompt : A hyper-realistic, a Japanese princess with waist-length black hair, a small glowing white crown, and a white cloak, sitting on a rock overlooking the floating island city of Aenos. The city has grandiose white towers and lush greenery. The sky has purple hues, and the scene has an air of anticipation and joy. Add flowers around the rock and in the foreground for a touch of color and fantasy.\n",
      "\n",
      "Image prompt A hyper-realistic image of a Japanese princess with waist-length black hair, wearing a small glowing white crown and a white cloak, sitting on a rock. She overlooks the floating island city of Aenos, characterized by grandiose white towers amidst lush greenery. The sky is painted in purple hues, conveying anticipation and joy. Flowers in vibrant colors surround the rock and fill the foreground, adding a fantasy element.\n",
      "Video prompt A hyper-realistic video focusing on a Japanese princess with waist-length black hair and a glowing white crown, sitti\n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec_llm.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-23 11:55:22,613] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 11:55:22,613] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 11:55:22,621] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 11:55:29,021] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 11:55:32,938] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 11:55:41,443] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 11:55:41,975] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 11:55:41,975] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||A hyper-realistic video focusing on a Japanese princess with waist-length black hair and a glowing white crown, sitti ...\n",
      "[2024-05-23 11:55:44,494] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 12:00:52,771] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_43EF19816_00.mp4:\n",
      "[2024-05-23 12:00:52,771] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_43EF19816_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/1.mp4\n",
      "[2024-05-23 12:00:55,501] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 12:00:55,501] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 12:00:55,509] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 12:01:02,060] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 12:01:05,952] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 12:01:14,463] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 12:01:14,991] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 12:01:14,991] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||A hyper-realistic video focusing on a Japanese princess with waist-length black hair and a glowing white crown, sitti ...\n",
      "[2024-05-23 12:01:17,528] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 12:06:26,525] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_1B0AB91C4_00.mp4:\n",
      "[2024-05-23 12:06:26,525] INFO: Congratulations! The inference is completed!\n",
      "Run 2 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_1B0AB91C4_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/2.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/2.mp4\n",
      "1.mp4\n",
      "2.mp4\n",
      "Concatenated video saved successfully!\n",
      "Original Prompt : a soldier in a mechanical tactical costume shaped as a mechanical phoenix, holds a gun, stands in a ruined city, in the style of the division, full body camera, in the style of the division 2, massurrealism, photo-realistic techniques, ultra detail,\n",
      "\n",
      "Image prompt A photo-realistic, ultra-detailed image of a soldier in a mechanical tactical costume shaped like a phoenix, holding a gun, standing in a ruined city. The style is reminiscent of The Division 2, blending massurrealism with full-body camera perspective. The environment is depicted with high fidelity, emphasizing the desolation and resilience.\n",
      "Video prompt A soldier in a mechanical phoenix-shaped tactical costume, holding a gun, stands amidst the ruins of a city. The vide\n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec_llm.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-23 12:06:59,027] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 12:06:59,028] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 12:06:59,035] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 12:07:05,625] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 12:07:09,565] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 12:07:18,122] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 12:07:18,649] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 12:07:18,649] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||A soldier in a mechanical phoenix-shaped tactical costume, holding a gun, stands amidst the ruins of a city. The vide ...\n",
      "[2024-05-23 12:07:21,177] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 12:12:06,259] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_303303B20_00.mp4:\n",
      "[2024-05-23 12:12:06,259] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_303303B20_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/1.mp4\n",
      "[2024-05-23 12:12:08,986] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 12:12:08,986] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 12:12:08,994] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 12:12:15,577] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 12:12:19,651] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 12:12:28,158] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 12:12:28,706] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 12:12:28,706] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||A soldier in a mechanical phoenix-shaped tactical costume, holding a gun, stands amidst the ruins of a city. The vide ...\n",
      "[2024-05-23 12:12:31,251] INFO: GPU Memory used 16.78 GB\n"
     ]
    }
   ],
   "source": [
    "prompts = open(\"vyom_prompts-llm.txt\").readlines()\n",
    "for prompt in prompts:\n",
    "    if prompt==\"\\n\":\n",
    "        continue\n",
    "    print(f\"Original Prompt : {prompt}\")\n",
    "    generated_prompts = llm_prompt_generator(prompt)\n",
    "    image_prompt = generated_prompts[\"Image_prompt\"]\n",
    "    video_prompt = generated_prompts[\"Video_prompt\"]\n",
    "    video_prompt = video_prompt[:117]\n",
    "    print(\"Image prompt\", image_prompt )\n",
    "    print(\"Video prompt\", video_prompt )\n",
    "    generator = Generator_9secs(\n",
    "                    image_prompt=image_prompt,\n",
    "                    video_prompt=video_prompt\n",
    "                )\n",
    "    generator.run_iterations(number_of_iterations=2) #Each iteration increases the video duration by 4 secs ( 32 frames )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e22de0-76db-45fc-88f3-e4c85da87f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898dcc3d-8a6a-4907-8daa-73ab1d1c8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.combine_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3dca45-da16-4bae-9701-ecfc237781d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 secs output videos in folder : 9secs_llm_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b724d1-a1ad-4099-8a38-1d07d7f6fb41",
   "metadata": {},
   "source": [
    "### PROMPTS\n",
    "A horse running on plains, beautiful sunlight behind it.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cinematic shot, woman in arctic clothing walking towards outpost, detailed face, cinematic contour lighting, building sitting on snowy hill in nepal, in the style of surrealistic dream-like imagery, ethereal cloudscapes, made of mist, conceptual installation art, hdr\n",
    "\n",
    "\n",
    "a girl holding a video camera to her head, in the style of hustlewave, 1980s, post-internet aesthetics, reefwave, wetcore, transavanguardia, childlike\n",
    "\n",
    "\n",
    "cinematic shot, greek temple on the top of cliff, electric lightsmoke & wire phenomenas, biblical event, movie aesthetic, super detailed, muted colours\n",
    "\n",
    "\n",
    "Photorealistic Busstop in Japan, Sakura Treens, Lofi Aesthetic, Minimalistic Cinematic Advertisement Aesthetic\n",
    "\n",
    "Arctic Norway Landscape showing Snowy Trollstung, muted colors, cinematic contour lighting, low contrast ProLog, awardwinning composition, chromatic aberration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b050ebc8-f47f-4f38-b826-aa6bf66697c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Image_prompt': 'An epic scene capturing the climax of a fantasy battle between heroes and villains. The heroes, in vibrant armor, are using their unique powers, with magic spells illuminating the scene. The villains counter with dark energy, creating a stark contrast. The focus is on the strategic positioning of both sides, showcasing a pivotal moment where the tide of battle could turn. The background is a devastated battlefield, hinting at the stakes of this confrontation.',\n",
       " 'Video_prompt': 'An epic scene capturing the climax of a fantasy battle between heroes and villains. The heroes, in vibrant armor, are using their unique powers, with magic spells illuminating the scene.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a380b-cd52-4445-847d-2f8d42420a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ff14c-c6e6-4ac1-bf37-15e639532aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
