{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea757ee8-1296-4572-8966-98738fbd2e80",
   "metadata": {},
   "source": [
    "### Generating 18 Secs video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f8a0f-d38b-40a5-bc3a-a22ac5e34d52",
   "metadata": {},
   "source": [
    "##### This section creates videos with 10 secs video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e0f535-7692-4ba7-b99e-48e39cd78f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c36c5-a2d9-43bd-bccc-cc9e85719435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import cv2\n",
    "import base64\n",
    "import requests\n",
    "os.environ[\"REPLICATE_API_TOKEN\"]=\"r8_N02JyR5WFnFG3DdksK9cuktBgmm9tP41kDXLj\"\n",
    "import replicate\n",
    "import subprocess\n",
    "\n",
    "api_key = \"sk-proj-pKaugqFY1WJ19hSq71lrT3BlbkFJVxwwYAMxPfQGX7G3eUOi\"\n",
    "os.environ[\"OPENAI_API_KEY\"]=api_key\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532138f-bd0c-4708-a280-082101b82499",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_9secs:\n",
    "\n",
    "    def __init__(self, prompt):\n",
    "        self.name = \"Generator\"\n",
    "        self.prompt = prompt\n",
    "        self.file_path = '18_sec_smooth.txt'\n",
    "        self.image_name = \"data/test_images/18_sec_smooth.jpg\"\n",
    "        self.command = [\n",
    "                    'python', 'inference.py',\n",
    "                    '--cfg', 'configs/i2vgen_xl_infer_smooth.yaml',\n",
    "                    'test_list_path', self.file_path,\n",
    "                    'test_model', 'models/i2vgen_xl_00854500.pth'\n",
    "                ]\n",
    "        with open(\"configs/i2vgen_xl_infer_smooth.yaml\") as f:\n",
    "            list_doc = yaml.safe_load(f)\n",
    "            list_doc[\"guide_scale\"] = 9\n",
    "\n",
    "        with open(\"configs/i2vgen_xl_infer_smooth.yaml\", \"w\") as f:\n",
    "            yaml.dump(list_doc, f)\n",
    "\n",
    "\n",
    "    def image_generator(self):\n",
    "        \"\"\"\n",
    "        Generates an image from a prompt using OpenAI's API and saves it locally.\n",
    "    \n",
    "        Parameters:\n",
    "        - prompt (str): The prompt to generate the image from.\n",
    "        - filename (str): The local filename to save the image.\n",
    "        \"\"\"\n",
    "        # Call the OpenAI API to generate the image\n",
    "        response = OpenAI().images.generate(\n",
    "          model=\"dall-e-3\",\n",
    "          prompt=self.prompt,\n",
    "          size=\"1024x1024\",\n",
    "          quality=\"standard\",\n",
    "          n=1,\n",
    "        )\n",
    "    \n",
    "        # Get the image URL from the response\n",
    "        image_url = dict(response)['data'][0].url\n",
    "    \n",
    "        # Download the image from the URL\n",
    "        image_response = requests.get(image_url)\n",
    "    \n",
    "        # Save the image to a file\n",
    "        with open(self.image_name, 'wb') as file:\n",
    "            file.write(image_response.content)\n",
    "    \n",
    "        print(f\"Image saved as {self.image_name}\")\n",
    "\n",
    "    def create_input_list(self):\n",
    "        test_data = f\"{self.image_name}|||{self.prompt}\"\n",
    "        # Open the file in write mode ('w') which will create the file if it doesn't exist\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            # Write the string to the file\n",
    "            file.write(test_data)\n",
    "\n",
    "    def save_last_frame(self, video_path):\n",
    "    \n",
    "        # Capture video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Couldn't open video file.\")\n",
    "            return\n",
    "    \n",
    "        last_frame = None\n",
    "    \n",
    "        # Read through the video\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            last_frame = frame\n",
    "    \n",
    "        # Save the last frame\n",
    "        if last_frame is not None:\n",
    "            cv2.imwrite(self.image_name, last_frame)\n",
    "            print(f\"Last frame saved to {self.image_name}\")\n",
    "        else:\n",
    "            print(\"No frames to save.\")\n",
    "    \n",
    "        # Release resources\n",
    "        cap.release()\n",
    "\n",
    "    def run_iterations(self, number_of_iterations=2):\n",
    "        print(\"Generating Image from Dalle-3\")\n",
    "        self.image_generator()\n",
    "        print(\"Creating Input list\")\n",
    "        self.create_input_list()\n",
    "\n",
    "        print(\"Removing earlier generated video\")\n",
    "        try:\n",
    "            subprocess.run(\"rm -rf workspace/experiments/18_sec_smooth/\")\n",
    "        except:\n",
    "            print(\"Folder not created yet.\")\n",
    "        \n",
    "        print(\"Runnning video generation\")\n",
    "        # subprocess.run(self.command) \n",
    "\n",
    "    \n",
    "        for i in range(number_of_iterations):\n",
    "\n",
    "            with open(\"configs/i2vgen_xl_infer_smooth.yaml\") as f:\n",
    "                list_doc = yaml.safe_load(f)\n",
    "                print(\"Running Iteration with guidance scale : \",list_doc[\"guide_scale\"])\n",
    "\n",
    "            print(\"Running...\")\n",
    "            # Execute the command\n",
    "            subprocess.run(self.command)\n",
    "            \n",
    "            # Print completion message\n",
    "            print(f\"Run {i+1} of the script completed\")\n",
    "        \n",
    "            # Specify the directory\n",
    "            directory = 'workspace/experiments/18_sec_smooth/'\n",
    "            \n",
    "            # Get list of files in the directory\n",
    "            files = [os.path.join(directory, f) for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and 'log' not in f]\n",
    "            \n",
    "            \n",
    "            # Find the latest file\n",
    "            latest_file = max(files, key=os.path.getctime)\n",
    "            new_name = os.path.join(directory, f'{i+1}.mp4')\n",
    "            \n",
    "            # Rename the latest file\n",
    "            os.rename(latest_file, new_name)\n",
    "            \n",
    "            print(f'Renamed \"{latest_file}\" to \"{new_name}\"')    \n",
    "\n",
    "            self.save_last_frame(new_name)\n",
    "            # self.denoise_image()\n",
    "            \n",
    "            print(f\"Saved frame from {new_name}\")\n",
    "    \n",
    "            with open(\"configs/i2vgen_xl_infer_smooth.yaml\") as f:\n",
    "                list_doc = yaml.safe_load(f)\n",
    "                list_doc[\"guide_scale\"] = max(1, list_doc[\"guide_scale\"] // 1.5)\n",
    "            \n",
    "            with open(\"configs/i2vgen_xl_infer_smooth.yaml\", \"w\") as f:\n",
    "                yaml.dump(list_doc, f)\n",
    "                    \n",
    "        \n",
    "\n",
    "        self.combine_videos()\n",
    "\n",
    "\n",
    "    def denoise_image(self):\n",
    "\n",
    "        with open(self.image_name, 'rb') as file:\n",
    "          data = base64.b64encode(file.read()).decode('utf-8')\n",
    "          image = f\"data:application/octet-stream;base64,{data}\"\n",
    "        \n",
    "        input = {\n",
    "            \"image\": image,\n",
    "            \"task_type\": \"Image Denoising\"\n",
    "        }\n",
    "        \n",
    "        output = replicate.run(\n",
    "            \"megvii-research/nafnet:018241a6c880319404eaa2714b764313e27e11f950a7ff0a7b5b37b27b74dcf7\",\n",
    "            input=input\n",
    "        )\n",
    "        data = requests.get(output).content \n",
    "        f = open(self.image_name,'wb') \n",
    "        f.write(data) \n",
    "        f.close() \n",
    "        print(\"Replaced image with denoised image\")\n",
    "          \n",
    "\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "    def combine_videos(self):\n",
    "        \n",
    "        # Path to the folder containing the videos\n",
    "        folder_path = \"workspace/experiments/18_sec_smooth\"\n",
    "        \n",
    "        # Get list of video files in the folder\n",
    "        video_files = [f for f in os.listdir(folder_path) if f.endswith('.mp4')]\n",
    "        \n",
    "        # Sort video files based on their names (assuming they are named numerically)\n",
    "        video_files.sort()\n",
    "        \n",
    "        # Initialize an empty list to store video frames\n",
    "        frames = []\n",
    "        \n",
    "        # Read each video and store frames\n",
    "        for video_file in video_files:\n",
    "            print(video_file)\n",
    "            video_path = os.path.join(folder_path, video_file)\n",
    "            video_capture = cv2.VideoCapture(video_path)\n",
    "        \n",
    "            while True:\n",
    "                success, frame = video_capture.read()\n",
    "                if not success:\n",
    "                    break\n",
    "                frames.append(frame)\n",
    "        \n",
    "            # Release video capture object after reading the video\n",
    "            video_capture.release()\n",
    "        \n",
    "        # Concatenate frames vertically (assuming all videos have the same resolution\n",
    "\n",
    "        os.makedirs(\"18_sec_smooth\", exist_ok = True)\n",
    "        \n",
    "        # Write the concatenated video to a file\n",
    "        output_path = \"18_sec_smooth/\" + str(self.prompt)+\".mp4\"\n",
    "        # fourcc = cv2.VideoWriter_fourcc(*'xvid') # Specify the codec\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # for MP4 codec\n",
    "        height, width, _ = frames[0].shape  # Get the dimensions from the first frame\n",
    "        out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 8, (width, height))\n",
    "        \n",
    "        for frame in frames:\n",
    "            out.write(frame)\n",
    "        \n",
    "        # Release the VideoWriter\n",
    "        out.release()\n",
    "        \n",
    "        print(\"Concatenated video saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88c826-7e4b-4ab7-8be4-577244d2d433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56adf7e-e759-437b-b917-d7a6835cc22e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"A person sitting on the beach and reading book\"\n",
    "print(f\"Prompt : {prompt}\")\n",
    "generator = Generator_9secs(prompt)\n",
    "\n",
    "generator.command = [\n",
    "                'python', 'inference.py',\n",
    "                '--cfg', 'configs/i2vgen_xl_infer_smooth.yaml',\n",
    "                'test_list_path', generator.file_path,\n",
    "                'test_model', 'models/i2vgen_xl_00854500.pth'\n",
    "            ]\n",
    "\n",
    "generator.run_iterations(number_of_iterations=5) #Each iteration increases the video duration by 4 secs ( 32 frames ).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2166b-3670-441d-92b7-a2c73a321fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3dca45-da16-4bae-9701-ecfc237781d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58b724d1-a1ad-4099-8a38-1d07d7f6fb41",
   "metadata": {},
   "source": [
    "### PROMPTS\n",
    "A horse running on plains, beautiful sunlight behind it.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cinematic shot, woman in arctic clothing walking towards outpost, detailed face, cinematic contour lighting, building sitting on snowy hill in nepal, in the style of surrealistic dream-like imagery, ethereal cloudscapes, made of mist, conceptual installation art, hdr\n",
    "\n",
    "\n",
    "a girl holding a video camera to her head, in the style of hustlewave, 1980s, post-internet aesthetics, reefwave, wetcore, transavanguardia, childlike\n",
    "\n",
    "\n",
    "cinematic shot, greek temple on the top of cliff, electric lightsmoke & wire phenomenas, biblical event, movie aesthetic, super detailed, muted colours\n",
    "\n",
    "\n",
    "Photorealistic Busstop in Japan, Sakura Treens, Lofi Aesthetic, Minimalistic Cinematic Advertisement Aesthetic\n",
    "\n",
    "Arctic Norway Landscape showing Snowy Trollstung, muted colors, cinematic contour lighting, low contrast ProLog, awardwinning composition, chromatic aberration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b050ebc8-f47f-4f38-b826-aa6bf66697c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
