{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8145b37f-90dc-496e-8abe-c815582ce57a",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0cd6e87-004d-43fa-a50e-5c5896973f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vyom_llm_utils import Generator_4secs, Generator_9secs, llm_prompt_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ffb62-8291-401e-b07b-cce07a600d87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generating 4 secs Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c32d6-fd83-43d4-8a0d-3fdc5f5e407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case you need to save the prompts from the notebook. Uncomment the code below.\n",
    "# prompts = \"\"\"\n",
    "# A horse running on plains, beautiful sunlight behind it. \\n\n",
    "# \"\"\"\n",
    "# # Open the file in write mode ('w') which will create the file if it doesn't exist\n",
    "# with open(\"vyom_prompts_1.txt\", 'w') as file:\n",
    "#     # Write the string to the file\n",
    "#     file.write(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2518f48-fbdb-435b-9b97-b55b4e1686bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = open(\"vyom_prompts-llm.txt\").readlines()\n",
    "for prompt in prompts:\n",
    "    if prompt==\"\\n\":\n",
    "        continue\n",
    "    print(f\"Original Prompt : {prompt}\")\n",
    "    generated_prompts = llm_prompt_generator(prompt)\n",
    "    image_prompt = generated_prompts[\"Image_prompt\"]\n",
    "    video_prompt = generated_prompts[\"Video_prompt\"]\n",
    "    print(\"Image prompt\", image_prompt )\n",
    "    print(\"Video prompt\", video_prompt )\n",
    "    generator = Generator_4secs(\n",
    "                    image_prompt=image_prompt,\n",
    "                    video_prompt=video_prompt\n",
    "                )\n",
    "    generator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038ba0d-7072-45ce-8b97-d49fc9236aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 secs output videos in : workspace/experiments/vyom_4sec_llm_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea757ee8-1296-4572-8966-98738fbd2e80",
   "metadata": {},
   "source": [
    "### Generating 9 Secs video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f8a0f-d38b-40a5-bc3a-a22ac5e34d52",
   "metadata": {},
   "source": [
    "##### This section creates videos with 10 secs video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2166b-3670-441d-92b7-a2c73a321fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Prompt : Dive into an alien ocean, focusing on exotic sea life and otherworldly landscapes\n",
      "\n",
      "Image prompt An alien ocean teeming with exotic sea life amidst otherworldly landscapes. Vivid colors and bioluminescent creatures illuminate the underwater scene, with fantastical plants and rock formations. The focus is on a particularly striking alien fish, showcasing its unique features against the backdrop of a surreal, deep-sea environment.\n",
      "Video prompt Explore an alien ocean, focusing on the vibrant, exotic sea life and surreal landscapes. The journey reveals biolumin\n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec_llm.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-23 07:41:04,885] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 07:41:04,885] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 07:41:04,892] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 07:41:10,947] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 07:41:14,747] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 07:41:23,256] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 07:41:23,784] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 07:41:23,784] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||Explore an alien ocean, focusing on the vibrant, exotic sea life and surreal landscapes. The journey reveals biolumin ...\n",
      "[2024-05-23 07:41:26,305] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 07:46:14,294] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_Explore_an_alien_ocean_focusing_on_the_vibrant_exotic_sea_life_and_surreal_landscapes_The_journey_reveals_biolumin_00.mp4:\n",
      "[2024-05-23 07:46:14,295] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_Explore_an_alien_ocean_focusing_on_the_vibrant_exotic_sea_life_and_surreal_landscapes_The_journey_reveals_biolumin_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/1.mp4\n",
      "[2024-05-23 07:46:16,920] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 07:46:16,920] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 07:46:16,927] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 07:46:22,952] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 07:46:26,705] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 07:46:35,180] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 07:46:35,711] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 07:46:35,711] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||Explore an alien ocean, focusing on the vibrant, exotic sea life and surreal landscapes. The journey reveals biolumin ...\n",
      "[2024-05-23 07:46:38,243] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 07:51:26,978] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_Explore_an_alien_ocean_focusing_on_the_vibrant_exotic_sea_life_and_surreal_landscapes_The_journey_reveals_biolumin_00.mp4:\n",
      "[2024-05-23 07:51:26,978] INFO: Congratulations! The inference is completed!\n",
      "Run 2 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_Explore_an_alien_ocean_focusing_on_the_vibrant_exotic_sea_life_and_surreal_landscapes_The_journey_reveals_biolumin_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/2.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/2.mp4\n",
      "1.mp4\n",
      "2.mp4\n",
      "Concatenated video saved successfully!\n",
      "Original Prompt : Explore a hidden garden where mythical creatures roam, highlighting its magic from day to night\n",
      "\n",
      "Image prompt A captivating image of a hidden garden, teeming with mythical creatures like unicorns and fairies, transitioning from the vibrant colors of day to the mystical glow of night. The garden is lush, with an ancient tree at its heart, under which creatures gather, illuminated by the soft, magical light.\n",
      "Video prompt Explore the hidden garden's transformation from day to night, capturing mythical creatures like unicorns and fairies \n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec_llm.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-23 07:51:46,610] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 07:51:46,610] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 07:51:46,617] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 07:51:52,666] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 07:51:56,381] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 07:52:04,838] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 07:52:05,359] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 07:52:05,359] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||Explore the hidden garden's transformation from day to night, capturing mythical creatures like unicorns and fairies ...\n",
      "[2024-05-23 07:52:07,889] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 07:56:56,454] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_Explore_the_hidden_gardens_transformation_from_day_to_night_capturing_mythical_creatures_like_unicorns_and_fairies_00.mp4:\n",
      "[2024-05-23 07:56:56,455] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_Explore_the_hidden_gardens_transformation_from_day_to_night_capturing_mythical_creatures_like_unicorns_and_fairies_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/1.mp4\n",
      "[2024-05-23 07:56:59,058] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 07:56:59,059] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 07:56:59,086] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 07:57:05,134] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 07:57:08,866] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 07:57:17,355] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 07:57:17,876] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 07:57:17,876] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||Explore the hidden garden's transformation from day to night, capturing mythical creatures like unicorns and fairies ...\n",
      "[2024-05-23 07:57:20,406] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 08:02:09,040] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_Explore_the_hidden_gardens_transformation_from_day_to_night_capturing_mythical_creatures_like_unicorns_and_fairies_00.mp4:\n",
      "[2024-05-23 08:02:09,040] INFO: Congratulations! The inference is completed!\n",
      "Run 2 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_Explore_the_hidden_gardens_transformation_from_day_to_night_capturing_mythical_creatures_like_unicorns_and_fairies_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/2.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/2.mp4\n",
      "1.mp4\n",
      "2.mp4\n",
      "Concatenated video saved successfully!\n",
      "Original Prompt : People searching for creative solutions. Teamwork business concept. Modern vector illustration of people connecting puzzle elements , white backgound\n",
      "\n",
      "Image prompt A modern vector illustration showcasing a diverse team of people collaboratively connecting puzzle pieces against a white background. The focus is on their hands and the puzzle pieces, symbolizing teamwork and creative problem-solving in a business context.\n",
      "Video prompt A dynamic illustration of a diverse team working together to connect puzzle pieces, symbolizing teamwork and creative\n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec_llm.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-23 08:02:31,930] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 08:02:31,930] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 08:02:31,937] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 08:02:37,967] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 08:02:41,717] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 08:02:50,180] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 08:02:50,710] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 08:02:50,710] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||A dynamic illustration of a diverse team working together to connect puzzle pieces, symbolizing teamwork and creative ...\n",
      "[2024-05-23 08:02:53,240] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 08:07:41,677] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_A_dynamic_illustration_of_a_diverse_team_working_together_to_connect_puzzle_pieces_symbolizing_teamwork_and_creative_00.mp4:\n",
      "[2024-05-23 08:07:41,677] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_A_dynamic_illustration_of_a_diverse_team_working_together_to_connect_puzzle_pieces_symbolizing_teamwork_and_creative_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/1.mp4\n",
      "[2024-05-23 08:07:44,254] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 08:07:44,254] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 08:07:44,261] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 08:07:50,304] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 08:07:54,038] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 08:08:02,531] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 08:08:03,064] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 08:08:03,064] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||A dynamic illustration of a diverse team working together to connect puzzle pieces, symbolizing teamwork and creative ...\n",
      "[2024-05-23 08:08:05,601] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 08:12:54,302] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_A_dynamic_illustration_of_a_diverse_team_working_together_to_connect_puzzle_pieces_symbolizing_teamwork_and_creative_00.mp4:\n",
      "[2024-05-23 08:12:54,302] INFO: Congratulations! The inference is completed!\n",
      "Run 2 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_A_dynamic_illustration_of_a_diverse_team_working_together_to_connect_puzzle_pieces_symbolizing_teamwork_and_creative_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/2.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/2.mp4\n",
      "1.mp4\n",
      "2.mp4\n",
      "Concatenated video saved successfully!\n",
      "Original Prompt : lavender field, Impressionism\n",
      "\n",
      "Image prompt An Impressionist-style image capturing the serene beauty of a lavender field at sunset. The brush strokes are soft and textured, blending purples, greens, and yellows to create a dreamy landscape. The focus is on the vast expanse of lavender, with a hint of a golden sun dipping below the horizon.\n",
      "Video prompt An Impressionist-style video capturing the serene beauty of a lavender field gently swaying in the breeze at sunset. \n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec_llm.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-23 08:13:17,263] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 08:13:17,263] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 08:13:17,271] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 08:13:23,497] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 08:13:27,329] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 08:13:35,819] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 08:13:36,361] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 08:13:36,361] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||An Impressionist-style video capturing the serene beauty of a lavender field gently swaying in the breeze at sunset. ...\n",
      "[2024-05-23 08:13:38,885] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 08:18:27,642] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_An_Impressioniststyle_video_capturing_the_serene_beauty_of_a_lavender_field_gently_swaying_in_the_breeze_at_sunset_00.mp4:\n",
      "[2024-05-23 08:18:27,643] INFO: Congratulations! The inference is completed!\n",
      "Run 1 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_An_Impressioniststyle_video_capturing_the_serene_beauty_of_a_lavender_field_gently_swaying_in_the_breeze_at_sunset_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/1.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/1.mp4\n",
      "[2024-05-23 08:18:30,232] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 08:18:30,232] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 08:18:30,239] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 08:18:36,300] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 08:18:40,089] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 08:18:48,609] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 08:18:49,150] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 08:18:49,150] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||An Impressionist-style video capturing the serene beauty of a lavender field gently swaying in the breeze at sunset. ...\n",
      "[2024-05-23 08:18:51,684] INFO: GPU Memory used 16.78 GB\n",
      "[2024-05-23 08:23:40,341] INFO: Save video to dir workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_An_Impressioniststyle_video_capturing_the_serene_beauty_of_a_lavender_field_gently_swaying_in_the_breeze_at_sunset_00.mp4:\n",
      "[2024-05-23 08:23:40,342] INFO: Congratulations! The inference is completed!\n",
      "Run 2 of the script completed\n",
      "Renamed \"workspace/experiments/vyom_9sec_llm_list/vyom_9sec_llm_01_00_An_Impressioniststyle_video_capturing_the_serene_beauty_of_a_lavender_field_gently_swaying_in_the_breeze_at_sunset_00.mp4\" to \"workspace/experiments/vyom_9sec_llm_list/2.mp4\"\n",
      "Last frame saved to data/test_images/vyom_9sec_llm.jpg\n",
      "Saved Last Video at workspace/experiments/vyom_9sec_llm_list/2.mp4\n",
      "1.mp4\n",
      "2.mp4\n",
      "Concatenated video saved successfully!\n",
      "Original Prompt : A succulent duck leg, perfectly cooked and glistening with flavorful juices, served atop a bed of creamy potato gratin and rich mushroom sauce. The crispy skin of the duck is golden and inviting, promising a delightful culinary experience.\n",
      "\n",
      "Image prompt A close-up image showcasing a succulent duck leg, perfectly cooked, with glistening, crispy golden skin, served on a bed of creamy potato gratin. The rich, dark mushroom sauce elegantly drizzles around the plate, enhancing the dish's appeal and promising a delightful culinary experience.\n",
      "Video prompt A close-up scene of a succulent duck leg, perfectly cooked, with glistening, crispy golden skin, being served on a be\n",
      "Generating Image from Dalle-3\n",
      "Image saved as data/test_images/vyom_9sec_llm.jpg\n",
      "Creating Input list\n",
      "Removing earlier generated video\n",
      "Folder not created yet.\n",
      "Runnning video generation\n",
      "[2024-05-23 08:24:04,710] INFO: {'__name__': 'Config: VideoLDM Decoder', 'mean': [0.5, 0.5, 0.5], 'std': [0.5, 0.5, 0.5], 'max_words': 1000, 'num_workers': 6, 'prefetch_factor': 2, 'resolution': [1280, 704], 'vit_out_dim': 1024, 'vit_resolution': [224, 224], 'depth_clamp': 10.0, 'misc_size': 384, 'depth_std': 20.0, 'frame_lens': [16, 16, 16, 16, 16, 32, 32, 32], 'sample_fps': [8, 8, 16, 16, 16, 8, 16, 16], 'vid_dataset': {'type': 'VideoDataset', 'data_list': ['data/vid_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/videos/'], 'vit_resolution': [224, 224], 'get_first_frame': True}, 'img_dataset': {'type': 'ImageDataset', 'data_list': ['data/img_list.txt'], 'max_words': 1000, 'resolution': [1280, 704], 'data_dir_list': ['data/images'], 'vit_resolution': [224, 224]}, 'batch_sizes': {'1': 32, '4': 8, '8': 4, '16': 2, '32': 1}, 'Diffusion': {'type': 'DiffusionDDIM', 'schedule': 'cosine', 'schedule_param': {'num_timesteps': 1000, 'cosine_s': 0.008, 'zero_terminal_snr': True}, 'mean_type': 'v', 'loss_type': 'mse', 'var_type': 'fixed_small', 'rescale_timesteps': False, 'noise_strength': 0.1, 'ddim_timesteps': 50}, 'ddim_timesteps': 50, 'use_div_loss': False, 'p_zero': 0.0, 'guide_scale': 9.0, 'vit_mean': [0.48145466, 0.4578275, 0.40821073], 'vit_std': [0.26862954, 0.26130258, 0.27577711], 'sketch_mean': [0.485, 0.456, 0.406], 'sketch_std': [0.229, 0.224, 0.225], 'hist_sigma': 10.0, 'scale_factor': 0.18215, 'use_checkpoint': True, 'use_sharded_ddp': False, 'use_fsdp': False, 'use_fp16': True, 'temporal_attention': True, 'UNet': {'type': 'UNetSD_I2VGen', 'in_dim': 4, 'dim': 320, 'y_dim': 1024, 'context_dim': 1024, 'out_dim': 4, 'dim_mult': [1, 2, 4, 4], 'num_heads': 8, 'head_dim': 64, 'num_res_blocks': 2, 'attn_scales': [1.0, 0.5, 0.25], 'dropout': 0.1, 'temporal_attention': True, 'temporal_attn_times': 1, 'use_checkpoint': True, 'use_fps_condition': False, 'use_sim_mask': False, 'upper_len': 128, 'concat_dim': 4, 'default_fps': 8}, 'guidances': [], 'auto_encoder': {'type': 'AutoencoderKL', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0, 'video_kernel_size': [3, 1, 1]}, 'embed_dim': 4, 'pretrained': 'models/v2-1_512-ema-pruned.ckpt'}, 'embedder': {'type': 'FrozenOpenCLIPTextVisualEmbedder', 'layer': 'penultimate', 'pretrained': 'models/open_clip_pytorch_model.bin', 'vit_resolution': [224, 224]}, 'ema_decay': 0.9999, 'num_steps': 1000000, 'lr': 3e-05, 'weight_decay': 0.0, 'betas': [0.9, 0.999], 'eps': 1e-08, 'chunk_size': 2, 'decoder_bs': 2, 'alpha': 0.7, 'save_ckp_interval': 50, 'warmup_steps': 10, 'decay_mode': 'cosine', 'use_ema': True, 'load_from': None, 'Pretrain': {'type': 'pretrain_specific_strategies', 'fix_weight': False, 'grad_scale': 0.5, 'resume_checkpoint': 'models/i2vgen_xl_00854500.pth', 'sd_keys_path': 'models/stable_diffusion_image_key_temporal_attention_x1.json'}, 'viz_interval': 50, 'visual_train': {'type': 'VisualTrainTextImageToVideo', 'partial_keys': [['y', 'image', 'local_image', 'fps']], 'use_offset_noise': True, 'guide_scale': 9.0}, 'visual_inference': {'type': 'VisualGeneratedVideos'}, 'inference_list_path': '', 'log_interval': 1, 'log_dir': 'workspace/experiments/vyom_9sec_llm_list', 'seed': 8888, 'negative_prompt': 'Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms', 'ENABLE': True, 'DATASET': 'webvid10m', 'TASK_TYPE': 'inference_i2vgen_entrance', 'max_frames': 32, 'target_fps': 16, 'scale': 8, 'round': 1, 'batch_size': 1, 'use_zero_infer': True, 'vldm_cfg': 'configs/i2vgen_xl_train.yaml', 'test_list_path': 'vyom_9sec_llm_list.txt', 'test_model': 'models/i2vgen_xl_00854500.pth', 'cfg_file': 'configs/i2vgen_xl_infer.yaml', 'init_method': 'tcp://localhost:9999', 'debug': False, 'opts': ['test_list_path', 'vyom_9sec_llm_list.txt', 'test_model', 'models/i2vgen_xl_00854500.pth'], 'pmi_rank': 0, 'pmi_world_size': 1, 'gpus_per_machine': 1, 'world_size': 1, 'noise_strength': 0.1, 'gpu': 0, 'rank': 0, 'log_file': 'workspace/experiments/vyom_9sec_llm_list/log_00.txt'}\n",
      "[2024-05-23 08:24:04,710] INFO: Going into it2v_fullid_img_text inference on 0 gpu\n",
      "[2024-05-23 08:24:04,717] INFO: Loading ViT-H-14 model config.\n",
      "[2024-05-23 08:24:10,812] INFO: Loading pretrained ViT-H-14 weights (models/open_clip_pytorch_model.bin).\n",
      "[2024-05-23 08:24:14,606] INFO: Restored from models/v2-1_512-ema-pruned.ckpt\n",
      "[2024-05-23 08:24:23,132] INFO: Load model from models/i2vgen_xl_00854500.pth with status <All keys matched successfully>\n",
      "[2024-05-23 08:24:23,671] INFO: There are 1 videos. with 1 times\n",
      "[2024-05-23 08:24:23,671] INFO: [0]/[1] Begin to sample data/test_images/vyom_9sec_llm.jpg|||A close-up scene of a succulent duck leg, perfectly cooked, with glistening, crispy golden skin, being served on a be ...\n",
      "[2024-05-23 08:24:26,202] INFO: GPU Memory used 16.78 GB\n"
     ]
    }
   ],
   "source": [
    "prompts = open(\"vyom_prompts-llm.txt\").readlines()\n",
    "for prompt in prompts:\n",
    "    if prompt==\"\\n\":\n",
    "        continue\n",
    "    print(f\"Original Prompt : {prompt}\")\n",
    "    generated_prompts = llm_prompt_generator(prompt)\n",
    "    image_prompt = generated_prompts[\"Image_prompt\"]\n",
    "    video_prompt = generated_prompts[\"Video_prompt\"]\n",
    "    video_prompt = video_prompt[:117]\n",
    "    print(\"Image prompt\", image_prompt )\n",
    "    print(\"Video prompt\", video_prompt )\n",
    "    generator = Generator_9secs(\n",
    "                    image_prompt=image_prompt,\n",
    "                    video_prompt=video_prompt\n",
    "                )\n",
    "    generator.run_iterations(number_of_iterations=2) #Each iteration increases the video duration by 4 secs ( 32 frames )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e22de0-76db-45fc-88f3-e4c85da87f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898dcc3d-8a6a-4907-8daa-73ab1d1c8c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.mp4\n",
      "2.mp4\n",
      "Concatenated video saved successfully!\n"
     ]
    }
   ],
   "source": [
    "generator.combine_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3dca45-da16-4bae-9701-ecfc237781d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 secs output videos in folder : 9secs_llm_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b724d1-a1ad-4099-8a38-1d07d7f6fb41",
   "metadata": {},
   "source": [
    "### PROMPTS\n",
    "A horse running on plains, beautiful sunlight behind it.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cinematic shot, woman in arctic clothing walking towards outpost, detailed face, cinematic contour lighting, building sitting on snowy hill in nepal, in the style of surrealistic dream-like imagery, ethereal cloudscapes, made of mist, conceptual installation art, hdr\n",
    "\n",
    "\n",
    "a girl holding a video camera to her head, in the style of hustlewave, 1980s, post-internet aesthetics, reefwave, wetcore, transavanguardia, childlike\n",
    "\n",
    "\n",
    "cinematic shot, greek temple on the top of cliff, electric lightsmoke & wire phenomenas, biblical event, movie aesthetic, super detailed, muted colours\n",
    "\n",
    "\n",
    "Photorealistic Busstop in Japan, Sakura Treens, Lofi Aesthetic, Minimalistic Cinematic Advertisement Aesthetic\n",
    "\n",
    "Arctic Norway Landscape showing Snowy Trollstung, muted colors, cinematic contour lighting, low contrast ProLog, awardwinning composition, chromatic aberration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b050ebc8-f47f-4f38-b826-aa6bf66697c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Image_prompt': 'An epic scene capturing the climax of a fantasy battle between heroes and villains. The heroes, in vibrant armor, are using their unique powers, with magic spells illuminating the scene. The villains counter with dark energy, creating a stark contrast. The focus is on the strategic positioning of both sides, showcasing a pivotal moment where the tide of battle could turn. The background is a devastated battlefield, hinting at the stakes of this confrontation.',\n",
       " 'Video_prompt': 'An epic scene capturing the climax of a fantasy battle between heroes and villains. The heroes, in vibrant armor, are using their unique powers, with magic spells illuminating the scene.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a380b-cd52-4445-847d-2f8d42420a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ff14c-c6e6-4ac1-bf37-15e639532aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
